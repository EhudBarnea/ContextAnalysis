{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# from keras import backend as K\n",
    "import keras \n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Flatten, GlobalAveragePooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, Callback\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import scipy.misc\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # suppress tensorflow \"wasn't compiled to use\" warnings\n",
    "# print(keras.__version__)\n",
    "\n",
    "\n",
    "from augment_dets import *\n",
    "from params import *\n",
    "from main import *\n",
    "from read_data_kitti_ssd import *\n",
    "\n",
    "# GPU number to use\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '2'\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = '3'\n",
    "\n",
    "out_folder = '../out/'\n",
    "data_folder = '../data/'\n",
    "tb_logs_dir = out_folder + 'logs/'\n",
    "num_out_classes = 80+1\n",
    "img_size = 224\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def gray2rgb(image):\n",
    "  rgb = np.empty([image.shape[0], image.shape[1], 3]).astype(np.uint8)\n",
    "  rgb[:,:,0] = image\n",
    "  rgb[:,:,1] = image\n",
    "  rgb[:,:,2] = image\n",
    "  return rgb\n",
    "\n",
    "def eval_pr(lbl, conf, correct, labels, num_objects, plot_fig=True):\n",
    "    # calculate precision-recall for detections (when we already have the correctness of detections)\n",
    "    # lbl - the label/type of objects to evaluate (int)\n",
    "    # conf - list of detections' confidence\n",
    "    # correct - correctness of each detection\n",
    "    # labels - label assigned to each detection (int)\n",
    "    # num_objects - total number of objects in the set\n",
    "    \n",
    "    # keep only relevant detections\n",
    "    relevant = labels == lbl\n",
    "    conf = conf[relevant]\n",
    "    correct = correct[relevant]\n",
    "    labels = labels[relevant]\n",
    "    \n",
    "    # sort detections by decreasing score across the whole set\n",
    "    sorted_id = np.argsort(-conf)\n",
    "    conf = conf[sorted_id]\n",
    "    correct = correct[sorted_id]\n",
    "\n",
    "    tp = correct\n",
    "    fp = np.logical_not(tp)\n",
    "\n",
    "    # compute precision / recall\n",
    "    fp = np.cumsum(fp)\n",
    "    tp = np.cumsum(tp)\n",
    "    rec = tp / num_objects\n",
    "    prec = np.divide(tp, (tp + fp))\n",
    "\n",
    "    # compute average precision\n",
    "    ap = 0\n",
    "    p_all = []\n",
    "    rec_points = np.arange(0, 1.01, 0.01)\n",
    "    for t in rec_points:\n",
    "        tmp = prec[rec >= t]\n",
    "        if len(tmp) == 0:\n",
    "            p = 0\n",
    "        else:\n",
    "            p = max(tmp)\n",
    "        ap += p / len(rec_points)\n",
    "        p_all.append(p)\n",
    "\n",
    "    ap_str = \"{0:.2f}\".format(ap)\n",
    "#     print(ap)\n",
    "    # print(ap_str)\n",
    "\n",
    "    if plot_fig:\n",
    "        plt.plot(rec_points, p_all)\n",
    "        plt.title('AP=' + ap_str)\n",
    "        plt.xlabel('recall')\n",
    "        plt.ylabel('precision')\n",
    "        plt.ylim((0, 1))\n",
    "        plt.xlim((0, 1))\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    return ap\n",
    "\n",
    "def prepare_batch(det_imgs, dets, det_ids, img_size, params):\n",
    "    # prepare detections batch to be fed to the network\n",
    "\n",
    "    # load and prepare data\n",
    "    labels_int = np.empty(len(det_ids))\n",
    "    data = np.empty([len(det_ids), img_size, img_size, 3])\n",
    "    prev_img_path = ''\n",
    "    for i, di in enumerate(det_ids):\n",
    "        d = dets[di]\n",
    "        det_img = det_imgs[di]\n",
    "\n",
    "        data[i] = det_img\n",
    "        if d['correct']:\n",
    "            labels_int[i] = params['object_labels'].index(d['label'])\n",
    "        else:\n",
    "            labels_int[i] = 80\n",
    "\n",
    "    data = preprocess_input(data)\n",
    "    labels = np_utils.to_categorical(labels_int, num_out_classes)\n",
    "\n",
    "    return data, labels\n",
    "\n",
    "def generate_batches(det_imgs, dets, det_ids, batch_size, img_size, params):\n",
    "    # batch generator for the training process\n",
    "    \n",
    "    # determine batches\n",
    "    num_samples = len(det_ids)\n",
    "    num_batches = int(np.ceil(num_samples / float(batch_size)))\n",
    "    batches = [(i * batch_size, min(num_samples, (i + 1) * batch_size)) \n",
    "               for i in range(0, num_batches)]\n",
    "    \n",
    "    while 1:  # do epoch\n",
    "        for b in batches:  # do single iteration/batch\n",
    "            x, y = prepare_batch(det_imgs, dets, det_ids[b[0]:b[1]], img_size, params)\n",
    "            yield (x, y)\n",
    "            \n",
    "def prep_det_img(img, d, img_size):\n",
    "    \n",
    "    # factor of width and height to add to the margin of the detection\n",
    "    det_size_factor = 0.1\n",
    "\n",
    "    img_height = img.shape[0]\n",
    "    img_width = img.shape[1]\n",
    "    img_limits = np.array([img_width-1, img_height-1, img_width-1, img_height-1])\n",
    "    # add enlarged gray rectangle over detection\n",
    "    det_width = d['x2'] - d['x1']\n",
    "    det_height = d['y2'] - d['y1']\n",
    "    det_xy = np.array([d['x1'], d['y1'], d['x2'], d['y2']])\n",
    "    det_xy += np.array([-det_width, -det_height, det_width, det_height]) * det_size_factor\n",
    "    det_xy[det_xy < 0] = 0\n",
    "    det_xy[det_xy >= img_limits] = img_limits[det_xy >= img_limits]\n",
    "    det_xy = det_xy.astype(np.int32)\n",
    "    \n",
    "    det_width = det_xy[2] - det_xy[0]\n",
    "    det_height = det_xy[3] - det_xy[1]\n",
    "    \n",
    "    det_img = np.copy(img)\n",
    "    det_img[det_xy[1]:det_xy[3], det_xy[0]:det_xy[2]] = np.ones([det_height,det_width,3])*127\n",
    "    det_img = scipy.misc.imresize(det_img, [img_size, img_size])\n",
    "    det_img = det_img.astype(np.uint8)\n",
    "    return det_img\n",
    "            \n",
    "def load_data(train_data, img_size, get_det_imgs, shuffle, params, num_imgs=-1):\n",
    "    # load detection and create detection images\n",
    "    \n",
    "    # load detections\n",
    "    if train_data:\n",
    "        data = read_data_coco_faster_rcnn(params, 'train', num_imgs)\n",
    "    else:\n",
    "        data = read_data_coco_faster_rcnn(params, 'both', num_imgs)\n",
    "    # add correctness and FP type to detections\n",
    "    num_positives = augment_dets(data, params)\n",
    "    # keep only relevant detections\n",
    "    dets = [d for d in data['dets'] if d['conf'] >= min_conf and not d['dont_care']]\n",
    "\n",
    "    # shuffle detections\n",
    "    if shuffle:\n",
    "        np.random.shuffle(dets)\n",
    "\n",
    "    # load images\n",
    "    print('loading images')\n",
    "    imgs = {}\n",
    "    for img_id in tqdm(data['imgs'].keys()):\n",
    "        if train_data:\n",
    "            img_path = params['imgs_folder'] + 'train/'+ 'COCO_train2014_000000' + str(img_id).rjust(6, '0') + '.jpg'\n",
    "        else:\n",
    "            img_path = params['imgs_folder'] + 'val/' + 'COCO_val2014_000000' + str(img_id).rjust(6, '0') + '.jpg'\n",
    "        img = plt.imread(img_path)\n",
    "        if len(img.shape) < 3:  # if grayscale convert to color\n",
    "            img = gray2rgb(img)\n",
    "        imgs[img_id] = img\n",
    "    print('done loading images')\n",
    "\n",
    "    # prepare detection images\n",
    "    det_imgs = []\n",
    "    if get_det_imgs:\n",
    "        print('creating detection images')\n",
    "        det_imgs = np.zeros([len(dets), img_size, img_size, 3])\n",
    "        for i, d in enumerate(tqdm(dets)):\n",
    "            img = imgs[d['img_id']]\n",
    "            det_img = prep_det_img(img, d, img_size)\n",
    "            det_imgs[i] = det_img\n",
    "        det_imgs = det_imgs.astype(np.uint8)\n",
    "        print('done creating detection images')\n",
    "\n",
    "        # free original images\n",
    "        imgs = []\n",
    "    \n",
    "    return dets, imgs, det_imgs, num_positives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare data and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading objects and detections\n",
      "augmenting detections\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6000/6000 [00:26<00:00, 227.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done augmenting detections\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 24/6000 [00:00<00:24, 239.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6000/6000 [00:25<00:00, 238.39it/s]\n",
      "  0%|          | 0/33984 [00:00<?, ?it/s]/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:125: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "  0%|          | 10/33984 [00:00<05:51, 96.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done loading images\n",
      "creating detection images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33984/33984 [02:52<00:00, 197.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done creating detection images\n",
      "num train samples = 27187\n",
      "num val samples = 6797\n",
      "num train TPs = 21379\n",
      "num train FPs = 5808\n",
      "ratio of FPs to TPs = 0.27166845970344733\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# minimum confidence detections to employ\n",
    "min_conf = 0.5\n",
    "# min_conf = -1\n",
    "# min_conf = 0.1\n",
    "params = get_params()\n",
    "\n",
    "# get detections and their images\n",
    "train_data = True\n",
    "shuffle = True\n",
    "get_det_imgs = True\n",
    "num_imgs = 6000\n",
    "dets, _, det_imgs, num_positives = load_data(train_data, img_size, get_det_imgs, shuffle, params, num_imgs=num_imgs)\n",
    "    \n",
    "# split to train and val\n",
    "num_train_samples = round(len(dets) * 0.8)\n",
    "train_det_ids = np.arange(num_train_samples)\n",
    "val_det_ids = np.arange(num_train_samples,len(dets))\n",
    "\n",
    "# count number of TPs and FPs\n",
    "num_tps = len([di for di in train_det_ids if dets[di]['correct']])\n",
    "num_fps = len(train_det_ids) - num_tps\n",
    "\n",
    "# calculate batch sizes\n",
    "batch_size = 32\n",
    "num_train_batches = int(np.ceil(len(train_det_ids) / float(batch_size)))\n",
    "num_val_batches = int(np.ceil(len(val_det_ids) / float(batch_size)))\n",
    "\n",
    "print('num train samples = ' + str(len(train_det_ids)))\n",
    "print('num val samples = ' + str(len(val_det_ids)))\n",
    "\n",
    "print('num train TPs = ' + str(num_tps))\n",
    "print('num train FPs = ' + str(num_fps))\n",
    "print('ratio of FPs to TPs = ' + str(num_fps/num_tps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create the base pre-trained model\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(img_size, img_size, 3))\n",
    "\n",
    "# add a fully connected output layer\n",
    "x = base_model.output\n",
    "\n",
    "# add top layers\n",
    "x = Flatten(name='flatten')(x)\n",
    "predictions = Dense(num_out_classes, activation='softmax', name='dense_last')(x)\n",
    "\n",
    "# create model for training\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# freeze convolutional layers\n",
    "for layer in base_model.layers[:-8]:\n",
    "    layer.trainable = False\n",
    "#     layer.trainable = True\n",
    "\n",
    "# optimiziers\n",
    "opt = keras.optimizers.SGD(lr=0.0001, momentum=0.0, decay=0.0, nesterov=False)\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorboard run: run_19\n",
      "Epoch 1/1000\n",
      "850/850 [==============================] - 210s - loss: 4.0460 - acc: 0.2644 - val_loss: 3.0572 - val_acc: 0.3128\n",
      "Epoch 2/1000\n",
      "850/850 [==============================] - 207s - loss: 2.9825 - acc: 0.3147 - val_loss: 2.8842 - val_acc: 0.3366\n",
      "Epoch 3/1000\n",
      "850/850 [==============================] - 207s - loss: 2.8171 - acc: 0.3334 - val_loss: 2.7657 - val_acc: 0.3532\n",
      "Epoch 4/1000\n",
      "850/850 [==============================] - 207s - loss: 2.6864 - acc: 0.3496 - val_loss: 2.6672 - val_acc: 0.3638\n",
      "Epoch 5/1000\n",
      "850/850 [==============================] - 207s - loss: 2.5769 - acc: 0.3636 - val_loss: 2.5941 - val_acc: 0.3697\n",
      "Epoch 6/1000\n",
      "850/850 [==============================] - 206s - loss: 2.4820 - acc: 0.3763 - val_loss: 2.5363 - val_acc: 0.3730\n",
      "Epoch 7/1000\n",
      "850/850 [==============================] - 206s - loss: 2.3982 - acc: 0.3872 - val_loss: 2.4887 - val_acc: 0.3791\n",
      "Epoch 8/1000\n",
      "850/850 [==============================] - 206s - loss: 2.3224 - acc: 0.3973 - val_loss: 2.4468 - val_acc: 0.3831\n",
      "Epoch 9/1000\n",
      "850/850 [==============================] - 206s - loss: 2.2524 - acc: 0.4100 - val_loss: 2.4126 - val_acc: 0.3908\n",
      "Epoch 10/1000\n",
      "850/850 [==============================] - 207s - loss: 2.1872 - acc: 0.4210 - val_loss: 2.3839 - val_acc: 0.3933\n",
      "Epoch 11/1000\n",
      "850/850 [==============================] - 206s - loss: 2.1255 - acc: 0.4311 - val_loss: 2.3589 - val_acc: 0.3983\n",
      "Epoch 12/1000\n",
      "850/850 [==============================] - 206s - loss: 2.0669 - acc: 0.4410 - val_loss: 2.3381 - val_acc: 0.4009\n",
      "Epoch 13/1000\n",
      "850/850 [==============================] - 206s - loss: 2.0107 - acc: 0.4512 - val_loss: 2.3199 - val_acc: 0.4065\n",
      "Epoch 14/1000\n",
      "850/850 [==============================] - 206s - loss: 1.9567 - acc: 0.4614 - val_loss: 2.3050 - val_acc: 0.4071\n",
      "Epoch 15/1000\n",
      "850/850 [==============================] - 206s - loss: 1.9044 - acc: 0.4717 - val_loss: 2.2907 - val_acc: 0.4097\n",
      "Epoch 16/1000\n",
      "850/850 [==============================] - 205s - loss: 1.8537 - acc: 0.4817 - val_loss: 2.2805 - val_acc: 0.4124\n",
      "Epoch 17/1000\n",
      "850/850 [==============================] - 206s - loss: 1.8047 - acc: 0.4911 - val_loss: 2.2721 - val_acc: 0.4117\n",
      "Epoch 18/1000\n",
      "850/850 [==============================] - 205s - loss: 1.7572 - acc: 0.5017 - val_loss: 2.2660 - val_acc: 0.4155501\n",
      "Epoch 19/1000\n",
      "850/850 [==============================] - 206s - loss: 1.7110 - acc: 0.5111 - val_loss: 2.2625 - val_acc: 0.4177\n",
      "Epoch 20/1000\n",
      "850/850 [==============================] - 206s - loss: 1.6660 - acc: 0.5203 - val_loss: 2.2616 - val_acc: 0.4189\n",
      "Epoch 21/1000\n",
      "850/850 [==============================] - 205s - loss: 1.6222 - acc: 0.5291 - val_loss: 2.2610 - val_acc: 0.4181\n",
      "Epoch 22/1000\n",
      "850/850 [==============================] - 206s - loss: 1.5791 - acc: 0.5372 - val_loss: 2.2617 - val_acc: 0.4197\n",
      "Epoch 23/1000\n",
      "850/850 [==============================] - 205s - loss: 1.5373 - acc: 0.5461 - val_loss: 2.2644 - val_acc: 0.4220\n",
      "Epoch 24/1000\n",
      "850/850 [==============================] - 205s - loss: 1.4962 - acc: 0.5547 - val_loss: 2.2694 - val_acc: 0.4246\n",
      "Epoch 25/1000\n",
      "850/850 [==============================] - 205s - loss: 1.4560 - acc: 0.5628 - val_loss: 2.2731 - val_acc: 0.4228\n",
      "Epoch 26/1000\n",
      "850/850 [==============================] - 205s - loss: 1.4163 - acc: 0.5715 - val_loss: 2.2794 - val_acc: 0.4231\n",
      "Epoch 27/1000\n",
      "850/850 [==============================] - 205s - loss: 1.3777 - acc: 0.5810 - val_loss: 2.2887 - val_acc: 0.4240\n",
      "Epoch 28/1000\n",
      "850/850 [==============================] - 205s - loss: 1.3395 - acc: 0.5908 - val_loss: 2.2995 - val_acc: 0.4220\n",
      "Epoch 29/1000\n",
      "850/850 [==============================] - 205s - loss: 1.3021 - acc: 0.5989 - val_loss: 2.3128 - val_acc: 0.4221\n",
      "Epoch 30/1000\n",
      "850/850 [==============================] - 205s - loss: 1.2655 - acc: 0.6080 - val_loss: 2.3238 - val_acc: 0.4227\n",
      "Epoch 31/1000\n",
      "850/850 [==============================] - 205s - loss: 1.2294 - acc: 0.6179 - val_loss: 2.3359 - val_acc: 0.424261\n",
      "Epoch 32/1000\n",
      "850/850 [==============================] - 205s - loss: 1.1944 - acc: 0.6264 - val_loss: 2.3508 - val_acc: 0.4249\n",
      "Epoch 33/1000\n",
      "850/850 [==============================] - 205s - loss: 1.1596 - acc: 0.6353 - val_loss: 2.3691 - val_acc: 0.4245\n",
      "Epoch 34/1000\n",
      "850/850 [==============================] - 205s - loss: 1.1254 - acc: 0.6428 - val_loss: 2.3865 - val_acc: 0.4228\n",
      "Epoch 35/1000\n",
      "850/850 [==============================] - 204s - loss: 1.0919 - acc: 0.6519 - val_loss: 2.4018 - val_acc: 0.4236\n",
      "Epoch 36/1000\n",
      "850/850 [==============================] - 205s - loss: 1.0588 - acc: 0.6618 - val_loss: 2.4252 - val_acc: 0.4212\n",
      "Epoch 37/1000\n",
      "850/850 [==============================] - 205s - loss: 1.0260 - acc: 0.6705 - val_loss: 2.4458 - val_acc: 0.4202\n",
      "Epoch 38/1000\n",
      "850/850 [==============================] - 205s - loss: 0.9942 - acc: 0.6811 - val_loss: 2.4716 - val_acc: 0.4192\n",
      "Epoch 39/1000\n",
      "850/850 [==============================] - 204s - loss: 0.9634 - acc: 0.6906 - val_loss: 2.4960 - val_acc: 0.4197\n",
      "Epoch 40/1000\n",
      "850/850 [==============================] - 205s - loss: 0.9327 - acc: 0.6997 - val_loss: 2.5242 - val_acc: 0.4175\n",
      "Epoch 41/1000\n",
      "850/850 [==============================] - 205s - loss: 0.9027 - acc: 0.7085 - val_loss: 2.5506 - val_acc: 0.4165\n",
      "Epoch 42/1000\n",
      "850/850 [==============================] - 205s - loss: 0.8729 - acc: 0.7163 - val_loss: 2.5805 - val_acc: 0.4162\n",
      "Epoch 43/1000\n",
      "850/850 [==============================] - 205s - loss: 0.8438 - acc: 0.7255 - val_loss: 2.6137 - val_acc: 0.4143\n",
      "Epoch 44/1000\n",
      "782/850 [==========================>...] - ETA: 14s - loss: 0.8153 - acc: 0.7353"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-c78900209531>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# start training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_train_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_val_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint_cb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensorboard_cb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2040\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2041\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2042\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2044\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1760\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1762\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1763\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2271\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2272\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2273\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# create generators\n",
    "train_gen = generate_batches(det_imgs, dets, train_det_ids, batch_size, img_size, params)\n",
    "val_gen = generate_batches(det_imgs, dets, val_det_ids, batch_size, img_size, params)\n",
    "\n",
    "# prepare callbacks\n",
    "checkpoint_cb = ModelCheckpoint(out_folder+'weights_{epoch:02d}.hdf5', period=1, save_weights_only=True)\n",
    "num_files = len(os.listdir(tb_logs_dir))\n",
    "run_name = 'run_' + str(num_files)\n",
    "tensorboard_cb = TensorBoard(log_dir=tb_logs_dir + run_name)\n",
    "print('Tensorboard run: ' + run_name)\n",
    "\n",
    "# start training\n",
    "hist = model.fit_generator(train_gen, steps_per_epoch=num_train_batches, epochs=1000, verbose=1, validation_data=val_gen, validation_steps=num_val_batches, callbacks=[checkpoint_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run model on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights\n",
      "Loading objects and detections\n",
      "augmenting detections\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40504/40504 [02:38<00:00, 255.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done augmenting detections\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 21/40504 [00:00<03:19, 202.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40504/40504 [02:49<00:00, 238.69it/s]\n",
      "  0%|          | 0/224144 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done loading images\n",
      "predict detections\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:125: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "100%|██████████| 224144/224144 [1:02:56<00:00, 59.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done predicting detections\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# minimum confidence detections to employ\n",
    "min_conf = 0.5\n",
    "# min_conf = -1\n",
    "# min_conf = 0.1\n",
    "params = get_params()\n",
    "\n",
    "# load weights\n",
    "print('Loading weights')\n",
    "model.load_weights(out_folder + '/weights_31.hdf5')\n",
    "\n",
    "# load images and detections\n",
    "train_data = False\n",
    "shuffle = False\n",
    "get_det_imgs = False\n",
    "num_imgs = -1\n",
    "dets, imgs, _, num_positives = load_data(train_data, img_size, get_det_imgs, shuffle, params, num_imgs=num_imgs)\n",
    "\n",
    "# prepare detection images and predict\n",
    "print('predict detections')\n",
    "pred_confs = []\n",
    "for i, d in enumerate(tqdm(dets)):\n",
    "    del_lbl = params['object_labels'].index(d['label'])\n",
    "    # prepare detection image\n",
    "    img = imgs[d['img_id']]\n",
    "    det_img = prep_det_img(img, d, img_size)\n",
    "    # prepare image for network\n",
    "    det_imgs = np.zeros([1, img_size, img_size, 3])\n",
    "    det_imgs[0] = det_img\n",
    "    det_imgs = preprocess_input(det_imgs)\n",
    "    # predict\n",
    "    preds = model.predict(det_imgs, batch_size=1, verbose=0)\n",
    "    pred_confs.append(preds[0][del_lbl])\n",
    "pred_confs = np.array(pred_confs);\n",
    "print('done predicting detections')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "4.17615486122\n",
      "bicycle\n",
      "10.0502052986\n",
      "car\n",
      "8.73227817738\n",
      "motorcycle\n",
      "6.66083477758\n",
      "airplane\n",
      "6.86793839023\n",
      "bus\n",
      "8.15933597356\n",
      "train\n",
      "5.57188270481\n",
      "truck\n",
      "9.94085713214\n",
      "boat\n",
      "10.1766197922\n",
      "traffic light\n",
      "8.19935344617\n",
      "fire hydrant\n",
      "5.31655701345\n",
      "stop sign\n",
      "7.6039012522\n",
      "parking meter\n",
      "7.28622899118\n",
      "bench\n",
      "9.95922350727\n",
      "bird\n",
      "4.94965286612\n",
      "cat\n",
      "8.35081908721\n",
      "dog\n",
      "8.44748199345\n",
      "horse\n",
      "8.69436928892\n",
      "sheep\n",
      "4.89798012348\n",
      "cow\n",
      "7.22303870424\n",
      "elephant\n",
      "8.35145303127\n",
      "bear\n",
      "10.4373560734\n",
      "zebra\n",
      "9.38325878632\n",
      "giraffe\n",
      "8.07086653272\n",
      "backpack\n",
      "6.41371649859\n",
      "umbrella\n",
      "8.02788688845\n",
      "handbag\n",
      "4.95095464738\n",
      "tie\n",
      "6.29489030924\n",
      "suitcase\n",
      "6.90540264811\n",
      "frisbee\n",
      "6.33509528987\n",
      "skis\n",
      "8.14176244785\n",
      "snowboard\n",
      "8.48019986342\n",
      "sports ball\n",
      "4.18207183324\n",
      "kite\n",
      "5.23615778196\n",
      "baseball bat\n",
      "6.19937512404\n",
      "baseball glove\n",
      "4.10327141821\n",
      "skateboard\n",
      "5.62226623787\n",
      "surfboard\n",
      "10.5197889762\n",
      "tennis racket\n",
      "4.52833161822\n",
      "bottle\n",
      "9.15350262394\n",
      "wine glass\n",
      "4.92852127295\n",
      "cup\n",
      "7.79235091334\n",
      "fork\n",
      "6.17876156031\n",
      "knife\n",
      "7.13976971211\n",
      "spoon\n",
      "4.90775882318\n",
      "bowl\n",
      "11.5762187872\n",
      "banana\n",
      "8.17371000851\n",
      "apple\n",
      "6.10309824476\n",
      "sandwich\n",
      "11.578675541\n",
      "orange\n",
      "9.64772058419\n",
      "broccoli\n",
      "10.0366638736\n",
      "carrot\n",
      "7.09701042262\n",
      "hot dog\n",
      "10.1060505987\n",
      "pizza\n",
      "10.4632218813\n",
      "donut\n",
      "6.98831593096\n",
      "cake\n",
      "12.2674936048\n",
      "chair\n",
      "7.01661270603\n",
      "couch\n",
      "9.02849376099\n",
      "potted plant\n",
      "10.3731490478\n",
      "bed\n",
      "17.4776764718\n",
      "dining table\n",
      "8.31905767738\n",
      "toilet\n",
      "13.3820621243\n",
      "tv\n",
      "9.66486941284\n",
      "laptop\n",
      "11.2753817971\n",
      "mouse\n",
      "6.69396461279\n",
      "remote\n",
      "7.72651710647\n",
      "keyboard\n",
      "13.0876383313\n",
      "cell phone\n",
      "8.60872288846\n",
      "microwave\n",
      "8.01915943356\n",
      "oven\n",
      "13.1488209894\n",
      "toaster\n",
      "12.7537803346\n",
      "sink\n",
      "12.6610036827\n",
      "refrigerator\n",
      "11.3580140207\n",
      "book\n",
      "4.33777377494\n",
      "clock\n",
      "6.6402975463\n",
      "vase\n",
      "9.45988243956\n",
      "scissors\n",
      "15.7955580302\n",
      "teddy bear\n",
      "12.3114717\n",
      "hair drier\n",
      "12.4969592782\n",
      "toothbrush\n",
      "14.1435975729\n"
     ]
    }
   ],
   "source": [
    "# prepare confidence and label of original detector\n",
    "test_labels = np.array([params['object_labels'].index(d['label']) for d in dets])\n",
    "test_corrects = np.array([d['correct'] for d in dets])\n",
    "test_confs = np.array([d['conf'] for d in dets])\n",
    "\n",
    "for lbl_int, lbl in enumerate(params['object_labels']):\n",
    "    print(lbl)\n",
    "    \n",
    "    # evaluate original detector\n",
    "#     print('Base detector:')\n",
    "    ap_base = eval_pr(lbl_int, test_confs, test_corrects, test_labels, num_positives[lbl], plot_fig=False)\n",
    "\n",
    "    # evaluate model\n",
    "#     print('Model:')\n",
    "    ap = eval_pr(lbl_int, pred_confs, test_corrects, test_labels, num_positives[lbl], plot_fig=False)\n",
    "    \n",
    "    print(100*(ap_base-ap))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Save predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "with open(out_folder + \"coco_nn_predictions_bigger_rect.txt\", \"w\") as out_file:\n",
    "    for i in range(len(dets)):\n",
    "        d = dets[i]\n",
    "        id_in_img = d['id_in_img']\n",
    "        img_id = d['img_id']\n",
    "        pred = pred_confs[i]\n",
    "        out_str = '%d,%d,%f\\n'%(id_in_img, img_id, pred)\n",
    "        out_file.write(out_str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
